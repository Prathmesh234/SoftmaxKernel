[project]
name = "b200triton"
version = "0.1.0"
description = "Flash Attention kernel optimized for NVIDIA B200 Blackwell GPUs using Triton"
readme = "README.md"
requires-python = ">=3.10"
dependencies = [
    "torch>=2.0.0",
    "triton>=3.0.0",
]

[project.scripts]
flash-attention = "flash_attention:main"
